{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket('caip_notebooks_demo_temp')\n",
    "blob = storage.Blob(\"train_df.csv\", bucket)\n",
    "train_df = pd.read_csv(StringIO(str(blob.download_as_string(),'utf-8')))\n",
    "blob = storage.Blob(\"test_df.csv\", bucket)\n",
    "test_df = pd.read_csv(StringIO(str(blob.download_as_string(),'utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Input functions\n",
    "\n",
    "[Estimator framework](https://www.tensorflow.org/get_started/premade_estimators#overview_of_programming_with_estimators) provides [input functions](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn) that wrap Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "# Training input on the whole training set with no limit on training epochs.\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"polarity\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "# Prediction on the whole training set.\n",
    "predict_train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    train_df, train_df[\"polarity\"], shuffle=False)\n",
    "# Prediction on the test set.\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    test_df, test_df[\"polarity\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns\n",
    "\n",
    "TF-Hub provides a [feature column](https://github.com/tensorflow/hub/blob/master/docs/api_docs/python/hub/text_embedding_column.md) that applies a module on the given text feature and passes further the outputs of the module. In this tutorial we will be using the [nnlm-en-dim128 module](https://tfhub.dev/google/nnlm-en-dim128/1). For the purpose of this tutorial, the most important facts are:\n",
    "\n",
    "* The module takes **a batch of sentences in a 1-D tensor of strings** as input.\n",
    "* The module is responsible for **preprocessing of sentences** (e.g. removal of punctuation and splitting on spaces).\n",
    "* The module works with any input (e.g. **nnlm-en-dim128** hashes words not present in vocabulary into ~20.000 buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "    key=\"sentence\", \n",
    "    module_spec=\"https://tfhub.dev/google/nnlm-en-dim128/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "For classification we can use a [DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) (note further remarks about different modelling of the label function at the end of the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm4yf25wz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm4yf25wz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_experimental_distribute': None, '_global_id_in_cluster': 0, '_train_distribute': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_is_chief': True, '_service': None, '_protocol': None, '_device_fn': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_max_worker_delay_secs': None, '_eval_distribute': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3a99e94a8>, '_evaluation_master': '', '_task_id': 0, '_model_dir': '/tmp/tmpm4yf25wz', '_master': '', '_session_creation_timeout_secs': 7200}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_experimental_distribute': None, '_global_id_in_cluster': 0, '_train_distribute': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_is_chief': True, '_service': None, '_protocol': None, '_device_fn': None, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_max_worker_delay_secs': None, '_eval_distribute': None, '_task_type': 'worker', '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc3a99e94a8>, '_evaluation_master': '', '_task_id': 0, '_model_dir': '/tmp/tmpm4yf25wz', '_master': '', '_session_creation_timeout_secs': 7200}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[500, 100],\n",
    "    feature_columns=[embedded_text_feature_column],\n",
    "    n_classes=2,\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Train the estimator for a reasonable amount of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpm4yf25wz/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpm4yf25wz/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88.42821, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88.42821, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tmpm4yf25wz/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2 into /tmp/tmpm4yf25wz/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 87.030464.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 87.030464.\n"
     ]
    }
   ],
   "source": [
    "# Training for 1,000 steps means 128,000 training examples with the default\n",
    "# batch size. This is roughly equivalent to 5 epochs since the training dataset\n",
    "# contains 25,000 examples.\n",
    "estimator.train(input_fn=train_input_fn, steps=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['classification', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['classification', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpm4yf25wz/model.ckpt-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpm4yf25wz/model.ckpt-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/temp-b'1576611704'/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/temp-b'1576611704'/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1576611704'/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1576611704'/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576606089/assets/tokens.txt#1576611676457268...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576606089/saved_model.pb#1576611676135790...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576606089/variables/variables.data-00000-of-00002#1576611675965270...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576606089/variables/variables.data-00001-of-00002#1576611686243030...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576606089/variables/variables.index#1576611675723877...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576608066/assets/tokens.txt#1576611676168166...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611381/assets/tokens.txt#1576611677264107...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611363/assets/tokens.txt#1576611676571906...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576608066/saved_model.pb#1576611675756963...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611363/saved_model.pb#1576611676140813...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576608066/variables/variables.data-00000-of-00002#1576611675582126...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611363/variables/variables.data-00001-of-00002#1576611686207578...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611381/variables/variables.index#1576611676283836...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611363/variables/variables.data-00000-of-00002#1576611676033009...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576608066/variables/variables.data-00001-of-00002#1576611686969367...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611381/saved_model.pb#1576611676534884...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611381/variables/variables.data-00000-of-00002#1576611676353428...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611363/variables/variables.index#1576611676191881...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611381/variables/variables.data-00001-of-00002#1576611688015133...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576608066/variables/variables.index#1576611675597701...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611428/assets/tokens.txt#1576611676278279...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611428/saved_model.pb#1576611676061732...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611428/variables/variables.data-00000-of-00002#1576611675441785...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611428/variables/variables.data-00001-of-00002#1576611686248395...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611428/variables/variables.index#1576611675548572...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611479/variables/variables.data-00000-of-00002#1576611676428928...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611479/assets/tokens.txt#1576611676995372...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611479/saved_model.pb#1576611676655027...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611479/variables/variables.data-00001-of-00002#1576611687369827...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611479/variables/variables.index#1576611676367016...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611640/assets/tokens.txt#1576611676919902...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611640/saved_model.pb#1576611676160810...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611640/variables/variables.data-00000-of-00002#1576611675666915...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611640/variables/variables.data-00001-of-00002#1576611687310726...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611640/variables/variables.index#1576611675938178...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611671/assets/tokens.txt#1576611676779900...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611671/saved_model.pb#1576611675936669...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611671/variables/variables.data-00000-of-00002#1576611675738606...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611671/variables/variables.data-00001-of-00002#1576611687690514...\n",
      "Removing gs://caip_notebooks_demo_temp/models/saved_model/1576611671/variables/variables.index#1576611676056354...\n",
      "/ [40/40 objects] 100% Done                                                     \n",
      "Operation completed over 40 objects.                                             \n",
      "Copying file://./saved_model/1576611428/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611428/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611428/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576611428/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611428/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run\n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://./saved_model/1576611640/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611640/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611640/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576606089/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576606089/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576606089/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576606089/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611640/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576608066/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576608066/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576606089/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576608066/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576608066/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576608066/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611640/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611671/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611671/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576611671/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611671/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611671/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611363/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611363/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576611363/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611363/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611363/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611381/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611381/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576611381/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611381/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611381/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611704/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611704/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576611704/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611704/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611704/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611479/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611479/assets/tokens.txt [Content-Type=text/plain]...\n",
      "Copying file://./saved_model/1576611479/variables/variables.data-00000-of-00002 [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611479/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./saved_model/1576611479/variables/variables.data-00001-of-00002 [Content-Type=application/octet-stream]...\n",
      "- [45/45 files][  4.3 GiB/  4.3 GiB] 100% Done  98.2 MiB/s ETA 00:00:00         \n",
      "Operation completed over 45 objects/4.3 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "def serving_input_receiver_fn():\n",
    "  text_input = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "  # embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "  # embedded_text = embed(text_input)\n",
    "  feed_dict={\"sentence\": text_input}\n",
    "  return tf.estimator.export.ServingInputReceiver(feed_dict, feed_dict)\n",
    "\n",
    "estimator.export_savedmodel('saved_model', serving_input_receiver_fn)\n",
    "# Removing old model (just in case)\n",
    "!gsutil -m rm -rf \"gs://caip_notebooks_demo_temp/models/saved_model/\"\n",
    "# Uploading latest model\n",
    "!gsutil -m cp -r \"./saved_model/*\" \"gs://caip_notebooks_demo_temp/models/saved_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
